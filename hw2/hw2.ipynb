{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ДЗ№2. LambdaRank или LambdaMART.\n",
    "1. Нужно самостоятельно реализовать метрики ранжирования MAP, MRR, NDCG (вместо семинара).\n",
    "2. Нужно реализовать алгоритм ранжирования LambdaRank или LambdaMART. Реализовать и то и другой будет плюсом. (см. ссылки ниже).\n",
    "3. Протестировать алгоритм на «стандартных» датасэтах MQ2007 и MQ2008 https://www.microsoft.com/en-us/research/project/letor-learning-rank-information-retrieval/letor-4-0/ (вычислите метрики из пункта 1)\n",
    "4. Применить алгоритм к дастасэту movielens https://grouplens.org/datasets/movielens/ . Считая, что оценка «5» – это релевантный фильм, «4» – это тоже релевантный фильм (но очевидно релевантность таких фильмов ниже, чем с оценкой «5»), остальные оценки не являются релевантными. Подумайте как адаптировать формат из \"стандартных\" датасэтов для ранжирования к задаче рекомендаций. Не поленитесь описать это комментарием в коде.\n",
    "5. Если вы делали ДЗ №1 то сравнить, ранжирование из пункта 4 с результатами «своего» SVD, если не делали то можно сравнить результаты с «чужого» SVD (например из библиотеки https://implicit.readthedocs.io/en/latest/quickstart.html , https://surprise.readthedocs.io/en/stable/getting_started.html)\n",
    " Насколько «качество» (определите качество самостоятельно - обоснуйте выбор) отличается на топ-3, топ-5, топ-10 фильмов?\n",
    "\n",
    "Ссылки:\n",
    "1. Основная статья: https://proceedings.neurips.cc/paper/2006/file/af44c4c56f385c43f2529f9b1b018f6a-Paper.pdf (запасная ссылка: https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/lambdarank.pdf )\n",
    "2. Также полезно почитать:\n",
    "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf \n",
    "https://www.cs.cmu.edu/~pinard/Papers/sigirfp092-donmez.pdf \n",
    "3. Примеры с формулами (но без подробностей):\n",
    "https://everdark.github.io/k9/notebooks/ml/learning_to_rank/learning_to_rank.html \n",
    "4. Можно повдохновляться кодом на «плюсах»:\n",
    "https://github.com/microsoft/LightGBM/blob/e79716e0b69b27c8e6e2c39f59d0db7c63242f9a/src/objective/rank_objective.hpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MQ2007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RankNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "         val_map            0.42127860696226627\n",
      "         val_mrr            0.4961145520210266\n",
      "        val_ndcg            0.6004802179719987\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Started at 07:11:00 07-11-2023\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | RankNet | 7.5 K \n",
      "----------------------------------\n",
      "7.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.5 K     Total params\n",
      "0.030     Total estimated model params size (MB)\n",
      "/home/ilya/repos/recsys/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "^C\n",
      "/home/ilya/repos/recsys/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "Finished at 07:13:02 07-11-2023\n",
      "Restoring states from the checkpoint path at ./logs/tb/ranknet-mq2007/version_1/checkpoints/epoch=27-step=24342.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./logs/tb/ranknet-mq2007/version_1/checkpoints/epoch=27-step=24342.ckpt\n"
     ]
    }
   ],
   "source": [
    "! python3 train.py --n_epochs 100 --name ranknet-mq2007 --model ranknet --dataset mq2007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LambdaRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: ./logs/tb/lambda-rank\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "         val_map            0.37902748197260233\n",
      "         val_mrr            0.4643586277961731\n",
      "        val_ndcg            0.5757187901830425\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Started at 02:37:46 07-11-2023\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | LambdaRank | 481   \n",
      "-------------------------------------\n",
      "481       Trainable params\n",
      "0         Non-trainable params\n",
      "481       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "/home/ilya/repos/recsys/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "Finished at 02:54:50 07-11-2023\n",
      "Restoring states from the checkpoint path at ./logs/tb/lambda-rank/version_0/checkpoints/epoch=243-step=212181.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./logs/tb/lambda-rank/version_0/checkpoints/epoch=243-step=212181.ckpt\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "         val_map             0.524850705746387\n",
      "         val_mrr             0.659218966960907\n",
      "        val_ndcg            0.6922078843133775\n",
      "────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "! python3 train.py --n_epochs 100 --name lambda-rank-mq2007 --model lambda-rank --dataset mq2007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MQ2008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RankNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: ./logs/tb/ranknet-mq2008\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "         val_map            0.4597659326486774\n",
      "         val_mrr            0.5387672185897827\n",
      "        val_ndcg            0.6045726895998438\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Started at 02:56:05 07-11-2023\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | RankNet | 481   \n",
      "----------------------------------\n",
      "481       Trainable params\n",
      "0         Non-trainable params\n",
      "481       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "/home/ilya/repos/recsys/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "Finished at 03:03:15 07-11-2023\n",
      "Restoring states from the checkpoint path at ./logs/tb/ranknet-mq2008/version_0/checkpoints/epoch=233-step=79281.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./logs/tb/ranknet-mq2008/version_0/checkpoints/epoch=233-step=79281.ckpt\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "         val_map            0.6076503494927425\n",
      "         val_mrr            0.6753336191177368\n",
      "        val_ndcg            0.7102101087235116\n",
      "────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "! python3 train.py --n_epochs 100 --model ranknet --name ranknet-mq2008 --dataset mq2008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LambdaRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "         val_map            0.4597659326486774\n",
      "         val_mrr            0.5387672185897827\n",
      "        val_ndcg            0.6045726895998438\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Started at 03:08:40 07-11-2023\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | LambdaRank | 481   \n",
      "-------------------------------------\n",
      "481       Trainable params\n",
      "0         Non-trainable params\n",
      "481       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "/home/ilya/repos/recsys/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "Finished at 03:16:03 07-11-2023\n",
      "Restoring states from the checkpoint path at ./logs/tb/lambda-rank--mq2008/version_1/checkpoints/epoch=173-step=58958.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./logs/tb/lambda-rank--mq2008/version_1/checkpoints/epoch=173-step=58958.ckpt\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "         val_map            0.6185547574009937\n",
      "         val_mrr            0.6874673366546631\n",
      "        val_ndcg            0.7187453670758929\n",
      "────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "! python3 train.py --n_epochs 100 --model lambda-rank --name lambda-rank-mq2008 --dataset mq2008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movielens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RankNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: ./logs/tb/ranknet-movielens\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "         val_map            0.6568911929808794\n",
      "        val_map@3           0.6904889364739476\n",
      "        val_map@5           0.6849393290506794\n",
      "         val_mrr            0.7249204516410828\n",
      "        val_ndcg            0.7013579896975339\n",
      "       val_ndcg@3           0.7169095369436539\n",
      "       val_ndcg@5           0.7192593655426587\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Started at 07:13:13 07-11-2023\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | RankNet | 7.4 K \n",
      "----------------------------------\n",
      "7.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.4 K     Total params\n",
      "0.029     Total estimated model params size (MB)\n",
      "/home/ilya/repos/recsys/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "^C\n",
      "/home/ilya/repos/recsys/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "Finished at 07:13:21 07-11-2023\n",
      "Restoring states from the checkpoint path at ./logs/tb/ranknet-movielens/version_0/checkpoints/epoch=0-step=931.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./logs/tb/ranknet-movielens/version_0/checkpoints/epoch=0-step=931.ckpt\n"
     ]
    }
   ],
   "source": [
    "! python3 train.py --n_epochs 100 --model ranknet --name ranknet-movielens --dataset movielens --user_based True --extra_metrics True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LambdaRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: ./logs/tb/lambda-rank-movielens\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "         val_map            0.6568911929808794\n",
      "        val_map@3           0.6904889364739476\n",
      "        val_map@5           0.6849393290506794\n",
      "         val_mrr            0.7249204516410828\n",
      "        val_ndcg            0.7013579896975339\n",
      "       val_ndcg@3           0.7169095369436539\n",
      "       val_ndcg@5           0.7192593655426587\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Started at 07:13:31 07-11-2023\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | LambdaRank | 7.4 K \n",
      "-------------------------------------\n",
      "7.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.4 K     Total params\n",
      "0.029     Total estimated model params size (MB)\n",
      "/home/ilya/repos/recsys/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "^C\n",
      "/home/ilya/repos/recsys/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "Finished at 07:13:40 07-11-2023\n",
      "Restoring states from the checkpoint path at ./logs/tb/lambda-rank-movielens/version_0/checkpoints/epoch=0-step=938.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./logs/tb/lambda-rank-movielens/version_0/checkpoints/epoch=0-step=938.ckpt\n"
     ]
    }
   ],
   "source": [
    "! python3 train.py --n_epochs 100 --model lambda-rank --name lambda-rank-movielens --dataset movielens --user_based True --extra_metrics True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def load(fname, path='/home/ilya/repos/recsys/data/ml-100k'):\n",
    "    path = os.path.join(path, fname)\n",
    "    return pd.read_csv(path, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp']).drop(columns=['timestamp'])\n",
    "\n",
    "def load_train():\n",
    "    return load('ua.base')\n",
    "def load_test():\n",
    "    return load('ua.test')\n",
    "\n",
    "df_train = load_train()\n",
    "df_test = load_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/repos/recsys/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ranking import svd\n",
    "\n",
    "hparams = dict(\n",
    "    n_factors=100,\n",
    "    n_epochs=10,\n",
    "    batch_size=128,\n",
    "    init_mean=0,\n",
    "    init_std_dev=.1,\n",
    "    biased=False,\n",
    "    lr=.03,\n",
    "    reg=.1,\n",
    "    random_state=0,\n",
    "    return_logs=False\n",
    ")\n",
    "\n",
    "df_train, df_test = svd(df_train, df_test, **hparams)\n",
    "df_test['rating'] = df_test['rating'].apply(lambda x: (x>3)*(x-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item(i, dataset, user_based):\n",
    "    if user_based:\n",
    "        mask = dataset.user_id == i\n",
    "    else:\n",
    "        mask = dataset.item_id == i\n",
    "\n",
    "    batch = dataset[mask]\n",
    "    y_true = batch['rating'].to_numpy()\n",
    "    y_score = batch['pred_rating'].to_numpy()\n",
    "\n",
    "    return y_true, y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = df_test.user_id.unique()\n",
    "\n",
    "targets = {}\n",
    "preds = {}\n",
    "for i in user_ids:\n",
    "    y_true, y_score = get_item(i, df_test, user_based=True)\n",
    "    if y_true.sum() == 0:\n",
    "        continue\n",
    "    targets[i] = y_true\n",
    "    preds[i] = y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10: 0.7943695821079642\n",
      "MRR: 0.8801073213011116\n",
      "NDCG@10: 0.8268825480566907\n"
     ]
    }
   ],
   "source": [
    "from ranking.metrics import MAP, MRR, NDCG\n",
    "\n",
    "print('MAP@10:', MAP(targets, preds))\n",
    "print('MRR:', MRR(targets, preds))\n",
    "print('NDCG@10:', NDCG(targets, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@5: 0.840051748750895\n",
      "NDCG@5: 0.8447014644841818\n"
     ]
    }
   ],
   "source": [
    "print('MAP@5:', MAP(targets, preds, k=5))\n",
    "print('NDCG@5:', NDCG(targets, preds, k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@3: 0.8570663811563188\n",
      "NDCG@3: 0.8519743548704194\n"
     ]
    }
   ],
   "source": [
    "print('MAP@3:', MAP(targets, preds, k=3))\n",
    "print('NDCG@3:', NDCG(targets, preds, k=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
